import asyncio
import requests
from aiogram import Bot, Dispatcher
from aiogram.types import Message
from aiogram.filters import CommandStart

BOT_TOKEN = "–í–°–¢–ê–í–¨_–¢–£–¢_–°–í–û–ô_–¢–û–ö–ï–ù"

# –ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –º–æ–¥–µ–ª—å HuggingFace –±–µ–∑ API –∫–ª—é—á–µ–π
HF_MODEL_URL = "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()


@dp.message(CommandStart())
async def start(message: Message):
    await message.answer(
        "ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π –ò–ò-–±–æ—Ç –Ω–∞ HuggingFace.\n"
        "–ó–∞–¥–∞–π –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å!"
    )


def ask_hf(prompt: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω—É—é HF –º–æ–¥–µ–ª—å"""

    if prompt is None:
        return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."

    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 200,
            "temperature": 0.7
        }
    }

    try:
        response = requests.post(HF_MODEL_URL, json=payload)
        data = response.json()

        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å "–∑–∞—Å–Ω—É–ª–∞" (HF –ø–æ–¥–≥—Ä—É–∂–∞–µ—Ç –µ—ë)
        if "error" in data:
            return "‚ö†Ô∏è –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥—Ä—É–∂–∞–µ—Ç—Å—è. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥."

        # HF –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        return data[0]["generated_text"]

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ HuggingFace: {e}"


@dp.message()
async def chat(message: Message):
    text = message.text

    await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

    reply = ask_hf(text)
    await message.answer(reply)


async def main():
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())